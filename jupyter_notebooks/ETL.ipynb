{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Online Retail transactions Dataset Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* For this project we gathered the raw data from Kaggle (https://www.kaggle.com/datasets/abhishekrp1517/online-retail-transactions-dataset/data). The objective of this notebook is to extract the raw data, transform it by cleaning and structuring it, and finally load the cleaned data into a new file for further analysis and visualisation.\n",
        "-Key goals include:\n",
        "-1. Data Cleaning: Handle missing values, remove duplicates, and correct inconsistencies.\n",
        "-2. Data Transformation: Convert data types, create new features, and structure the data for analysis.\n",
        "-3. Data Loading: Save the cleaned and transformed data into a new file format for ease of use and also to reduce file size.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* The raw dataset file \"Online Retail.csv\" located in the \"DataSet/Raw\" directory. We also used Python libraries such as pandas and numpy for data manipulation and analysis.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* The final cleaned and transformed dataset saved as \"fact_sales_clean.zip\" in the \"DataSet/Cleaned\" directory. This file is in CSV format and compressed to reduce file size.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* The cleaned dataset is now ready for further analysis and visualization tasks. The transformations applied ensure that the data is consistent, accurate, and structured in a way that facilitates insightful analysis. We found a few duplicates and missing values which is displayed and noted in the cleaning process. We also created a new feature \"TotalPrice\" to enhance our analysis capabilities for future use. In addition to this we also changed the names of some countries to help users better understand the data (EIRE to Ireland), and grouped sales by categories to aid in future analysis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\'"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\'"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 1 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "# Load raw data\n",
        "# Encoding 'ISO-8859-1' is used to handle special characters in the dataset\n",
        "df = pd.read_csv(r\"C:\\Users\\Nine\\OneDrive\\Documents\\VS Code Projects\\online-retail-transactions-analysis\\DataSet\\Raw\\Online Retail.csv\", encoding='ISO-8859-1')\n",
        "df.head()\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 541909 entries, 0 to 541908\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   InvoiceNo    541909 non-null  object \n",
            " 1   StockCode    541909 non-null  object \n",
            " 2   Description  540455 non-null  object \n",
            " 3   Quantity     541909 non-null  int64  \n",
            " 4   InvoiceDate  541909 non-null  object \n",
            " 5   UnitPrice    541909 non-null  float64\n",
            " 6   CustomerID   541909 non-null  int64  \n",
            " 7   Country      541909 non-null  object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 33.1+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values per column:\n",
            " InvoiceNo         0\n",
            "StockCode         0\n",
            "Description    1454\n",
            "Quantity          0\n",
            "InvoiceDate       0\n",
            "UnitPrice         0\n",
            "CustomerID        0\n",
            "Country           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count null values per column\n",
        "print(\"Missing values per column:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after dropping missing Descriptions: (540455, 8)\n",
            "Remaining null values:\n",
            " InvoiceNo      0\n",
            "StockCode      0\n",
            "Description    0\n",
            "Quantity       0\n",
            "InvoiceDate    0\n",
            "UnitPrice      0\n",
            "CustomerID     0\n",
            "Country        0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Drop rows where Description is missing\n",
        "df = df.dropna(subset=[\"Description\"])\n",
        "\n",
        "print(\"Shape after dropping missing Descriptions:\", df.shape)\n",
        "print(\"Remaining null values:\\n\", df.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicate rows: 5268\n"
          ]
        }
      ],
      "source": [
        "# Check duplicates\n",
        "print(\"Duplicate rows:\", df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>536409</td>\n",
              "      <td>22111</td>\n",
              "      <td>SCOTTIE DOG HOT WATER BOTTLE</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-12-01 11:45:00</td>\n",
              "      <td>4.95</td>\n",
              "      <td>17908</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>536409</td>\n",
              "      <td>22866</td>\n",
              "      <td>HAND WARMER SCOTTY DOG DESIGN</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-12-01 11:45:00</td>\n",
              "      <td>2.10</td>\n",
              "      <td>17908</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>536409</td>\n",
              "      <td>21866</td>\n",
              "      <td>UNION JACK FLAG LUGGAGE TAG</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-12-01 11:45:00</td>\n",
              "      <td>1.25</td>\n",
              "      <td>17908</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>536409</td>\n",
              "      <td>21866</td>\n",
              "      <td>UNION JACK FLAG LUGGAGE TAG</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-12-01 11:45:00</td>\n",
              "      <td>1.25</td>\n",
              "      <td>17908</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>536409</td>\n",
              "      <td>22900</td>\n",
              "      <td>SET 2 TEA TOWELS I LOVE LONDON</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-12-01 11:45:00</td>\n",
              "      <td>2.95</td>\n",
              "      <td>17908</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541675</th>\n",
              "      <td>581538</td>\n",
              "      <td>22068</td>\n",
              "      <td>BLACK PIRATE TREASURE CHEST</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-12-09 11:34:00</td>\n",
              "      <td>0.39</td>\n",
              "      <td>14446</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541689</th>\n",
              "      <td>581538</td>\n",
              "      <td>23318</td>\n",
              "      <td>BOX OF 6 MINI VINTAGE CRACKERS</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-12-09 11:34:00</td>\n",
              "      <td>2.49</td>\n",
              "      <td>14446</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541692</th>\n",
              "      <td>581538</td>\n",
              "      <td>22992</td>\n",
              "      <td>REVOLVER WOODEN RULER</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-12-09 11:34:00</td>\n",
              "      <td>1.95</td>\n",
              "      <td>14446</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541699</th>\n",
              "      <td>581538</td>\n",
              "      <td>22694</td>\n",
              "      <td>WICKER STAR</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-12-09 11:34:00</td>\n",
              "      <td>2.10</td>\n",
              "      <td>14446</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541701</th>\n",
              "      <td>581538</td>\n",
              "      <td>23343</td>\n",
              "      <td>JUMBO BAG VINTAGE CHRISTMAS</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-12-09 11:34:00</td>\n",
              "      <td>2.08</td>\n",
              "      <td>14446</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10147 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       InvoiceNo StockCode                       Description  Quantity  \\\n",
              "485       536409     22111      SCOTTIE DOG HOT WATER BOTTLE         1   \n",
              "489       536409     22866     HAND WARMER SCOTTY DOG DESIGN         1   \n",
              "494       536409     21866       UNION JACK FLAG LUGGAGE TAG         1   \n",
              "517       536409     21866       UNION JACK FLAG LUGGAGE TAG         1   \n",
              "521       536409     22900   SET 2 TEA TOWELS I LOVE LONDON          1   \n",
              "...          ...       ...                               ...       ...   \n",
              "541675    581538     22068       BLACK PIRATE TREASURE CHEST         1   \n",
              "541689    581538     23318    BOX OF 6 MINI VINTAGE CRACKERS         1   \n",
              "541692    581538     22992            REVOLVER WOODEN RULER          1   \n",
              "541699    581538     22694                      WICKER STAR          1   \n",
              "541701    581538     23343      JUMBO BAG VINTAGE CHRISTMAS          1   \n",
              "\n",
              "                InvoiceDate  UnitPrice  CustomerID         Country  \n",
              "485     2010-12-01 11:45:00       4.95       17908  United Kingdom  \n",
              "489     2010-12-01 11:45:00       2.10       17908  United Kingdom  \n",
              "494     2010-12-01 11:45:00       1.25       17908  United Kingdom  \n",
              "517     2010-12-01 11:45:00       1.25       17908  United Kingdom  \n",
              "521     2010-12-01 11:45:00       2.95       17908  United Kingdom  \n",
              "...                     ...        ...         ...             ...  \n",
              "541675  2011-12-09 11:34:00       0.39       14446  United Kingdom  \n",
              "541689  2011-12-09 11:34:00       2.49       14446  United Kingdom  \n",
              "541692  2011-12-09 11:34:00       1.95       14446  United Kingdom  \n",
              "541699  2011-12-09 11:34:00       2.10       14446  United Kingdom  \n",
              "541701  2011-12-09 11:34:00       2.08       14446  United Kingdom  \n",
              "\n",
              "[10147 rows x 8 columns]"
            ]
          },
          "execution_count": 268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#here we will check where the duplicates are\n",
        "df[df.duplicated(keep=False)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after removing duplicates: (535187, 8)\n",
            "Remaining duplicate rows: 0\n"
          ]
        }
      ],
      "source": [
        "# Drop duplicate rows\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"Shape after removing duplicates:\", df.shape)\n",
        "print(\"Remaining duplicate rows:\", df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "           InvoiceDate  UnitPrice  CustomerID         Country  \n",
            "0  2010-12-01 08:26:00       2.55       17850  United Kingdom  \n",
            "1  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "2  2010-12-01 08:26:00       2.75       17850  United Kingdom  \n",
            "3  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n",
            "4  2010-12-01 08:26:00       3.39       17850  United Kingdom  \n"
          ]
        }
      ],
      "source": [
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 535187 entries, 0 to 541908\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   InvoiceNo    535187 non-null  object \n",
            " 1   StockCode    535187 non-null  object \n",
            " 2   Description  535187 non-null  object \n",
            " 3   Quantity     535187 non-null  int64  \n",
            " 4   InvoiceDate  535187 non-null  object \n",
            " 5   UnitPrice    535187 non-null  float64\n",
            " 6   CustomerID   535187 non-null  int64  \n",
            " 7   Country      535187 non-null  object \n",
            "dtypes: float64(1), int64(2), object(5)\n",
            "memory usage: 36.7+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Normalize column names\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "for col in [\"InvoiceNo\",\"StockCode\",\"Description\",\"Country\"]:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].astype(str).str.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null InvoiceDate: 0\n",
            "Blank StockCode: 0\n",
            "Blank InvoiceNo: 0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country]\n",
              "Index: []"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"Null InvoiceDate:\", df['InvoiceDate'].isna().sum())\n",
        "print(\"Blank StockCode:\", (df['StockCode'].astype(str).str.strip()==\"\").sum())\n",
        "print(\"Blank InvoiceNo:\", (df['InvoiceNo'].astype(str).str.strip()==\"\").sum())\n",
        "\n",
        "# Show sample of bad rows (if any)\n",
        "display(df[df['InvoiceDate'].isna()].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current shape: (535187, 8)\n"
          ]
        }
      ],
      "source": [
        "#Rechecking the dataframe info\n",
        "print(\"Current shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InvoiceNo       object\n",
            "StockCode       object\n",
            "Description     object\n",
            "Quantity         int64\n",
            "InvoiceDate     object\n",
            "UnitPrice      float64\n",
            "CustomerID       int64\n",
            "Country         object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Changing InvoiceDate to datetime format to avoid any future issues\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InvoiceNo              object\n",
            "StockCode              object\n",
            "Description            object\n",
            "Quantity                int64\n",
            "InvoiceDate    datetime64[ns]\n",
            "UnitPrice             float64\n",
            "CustomerID              int64\n",
            "Country                object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique invoices: 24446\n",
            "Unique products: 3958\n",
            "Unique customers: 4372\n",
            "Unique countries: 38\n"
          ]
        }
      ],
      "source": [
        "#Looking for any unique values in invoice, stockcode, customerid and country\n",
        "print(\"Unique invoices:\", df['InvoiceNo'].nunique())\n",
        "print(\"Unique products:\", df['StockCode'].nunique())\n",
        "print(\"Unique customers:\", df['CustomerID'].nunique())\n",
        "print(\"Unique countries:\", df['Country'].nunique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cancelled invoices: 9251\n"
          ]
        }
      ],
      "source": [
        "# Identify and count cancelled invoices\n",
        "# We will keep these values in the dataset to analyse customer returns in DataVisualisation\n",
        "\n",
        "cancelled = df[df['InvoiceNo'].str.startswith('C')]\n",
        "print(\"Cancelled invoices:\", cancelled.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Quantity  UnitPrice  TotalSales\n",
            "0         6       2.55       15.30\n",
            "1         6       3.39       20.34\n",
            "2         8       2.75       22.00\n",
            "3         6       3.39       20.34\n",
            "4         6       3.39       20.34\n"
          ]
        }
      ],
      "source": [
        "# After speaking with my team we have decided an additioannal field for Total Sales should be added, this will consist of Quantity and Unit Price\n",
        "\n",
        "# Create a new field TotalSales = Quantity * UnitPrice\n",
        "df['TotalSales'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "\n",
        "# Quick check\n",
        "print(df[['Quantity','UnitPrice','TotalSales']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count    535187.000000\n",
            "mean         18.173100\n",
            "std         381.171824\n",
            "min     -168469.600000\n",
            "25%           3.750000\n",
            "50%           9.900000\n",
            "75%          17.400000\n",
            "max      168469.600000\n",
            "Name: TotalSales, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(df['TotalSales'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Above we can see that there are some negative values in TotalSales, these are due to cancelled orders and returns. We will keep these values for analysis in DataVisualisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique countries before:\n",
            "['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
            " 'EIRE' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy' 'Belgium'\n",
            " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cyprus'\n",
            " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
            " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
            " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'USA'\n",
            " 'European Community' 'Malta' 'RSA']\n",
            "\n",
            "Unique countries after:\n",
            "['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
            " 'Ireland' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy' 'Belgium'\n",
            " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cyprus'\n",
            " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
            " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
            " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'USA'\n",
            " 'European Community' 'Malta' 'South Africa']\n"
          ]
        }
      ],
      "source": [
        "# List all countries\n",
        "print(\"Unique countries before:\")\n",
        "print(df[\"Country\"].unique())\n",
        "\n",
        "# Replace EIRE to Ireland\n",
        "df[\"Country\"] = df[\"Country\"].replace(\"EIRE\", \"Ireland\")\n",
        "\n",
        "# Repleace RSA to South Africa\n",
        "df[\"Country\"] = df[\"Country\"].replace(\"RSA\", \"South Africa\")\n",
        "\n",
        "# Quick check\n",
        "print(\"\\nUnique countries after:\")\n",
        "print(df[\"Country\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows & share for questionable countries:\n",
            "\n",
            "European Community | rows=    61 |  0.01%\n",
            "Unspecified        | rows=   442 |  0.08%\n"
          ]
        }
      ],
      "source": [
        "# Here i have used AI to identify questionable country names and their data\n",
        "# The data will be removed from the dataset as they only represent a small fraction of the data (under 0.9% combined)\n",
        "\n",
        "odd = [\"European Community\", \"Unspecified\"]\n",
        "print(\"Rows & share for questionable countries:\\n\")\n",
        "for c in odd:\n",
        "    mask = df[\"Country\"].eq(c)\n",
        "    n = mask.sum()\n",
        "    pct = n / len(df) * 100\n",
        "    print(f\"{c:<18} | rows={n:>6,} | {pct:5.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape after removing questionable countries: (534684, 9)\n"
          ]
        }
      ],
      "source": [
        "df = df[~df[\"Country\"].isin(odd)]\n",
        "print(\"\\nShape after removing questionable countries:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Unique countries after:\n",
            "['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
            " 'Ireland' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy' 'Belgium'\n",
            " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cyprus'\n",
            " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
            " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
            " 'Czech Republic' 'Canada' 'Brazil' 'USA' 'Malta' 'South Africa']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nUnique countries after:\")\n",
        "print(df[\"Country\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We will now start the grouping section of the ETL process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InvoiceDate\n",
            "2010-12     746723.610\n",
            "2011-01     558448.560\n",
            "2011-02     497026.410\n",
            "2011-03     682013.980\n",
            "2011-04     491877.341\n",
            "2011-05     721038.230\n",
            "2011-06     689367.900\n",
            "2011-07     678061.081\n",
            "2011-08     680855.430\n",
            "2011-09    1017312.382\n",
            "2011-10    1069368.230\n",
            "2011-11    1455180.050\n",
            "2011-12     432701.060\n",
            "Freq: M, Name: TotalSales, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#This group will report total sales by month, to see which months were the most profitable\n",
        "sales_by_month = df.groupby(df['InvoiceDate'].dt.to_period('M'))['TotalSales'].sum()\n",
        "\n",
        "print(sales_by_month)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Description\n",
            "DOTCOM POSTAGE                        206245.48\n",
            "REGENCY CAKESTAND 3 TIER              164433.99\n",
            "WHITE HANGING HEART T-LIGHT HOLDER     99612.42\n",
            "PARTY BUNTING                          98243.88\n",
            "JUMBO BAG RED RETROSPOT                92175.79\n",
            "RABBIT NIGHT LIGHT                     66634.59\n",
            "POSTAGE                                66089.64\n",
            "PAPER CHAIN KIT 50'S CHRISTMAS         63715.24\n",
            "ASSORTED COLOUR BIRD ORNAMENT          58755.24\n",
            "CHILLI LIGHTS                          53746.66\n",
            "Name: TotalSales, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# This group will display the top 10 highest selling products by total sales amount.\n",
        "# We can change the amount by changing .head(10)) to a larger number to see more products\n",
        "\n",
        "top_products = df.groupby('Description')['TotalSales'].sum().sort_values(ascending=False).head(10)\n",
        "print(top_products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CustomerID\n",
            "15287    1445892.60\n",
            "14646     279489.02\n",
            "18102     256438.49\n",
            "17450     187322.17\n",
            "14911     132458.73\n",
            "12415     123725.45\n",
            "14156     113214.59\n",
            "17511      88125.38\n",
            "16684      65892.08\n",
            "13694      62690.54\n",
            "Name: TotalSales, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#This group will display the top 10 customers by sales value\n",
        "#We can change the amount by changing .head(10)) to a larger number to see more customers\n",
        "\n",
        "customer_sales = df.groupby('CustomerID')['TotalSales'].sum().sort_values(ascending=False)\n",
        "print(customer_sales.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Country\n",
            "United Kingdom    8167128.184\n",
            "Netherlands        284661.540\n",
            "Ireland            262993.380\n",
            "Germany            221509.470\n",
            "France             197317.110\n",
            "Australia          137009.770\n",
            "Switzerland         56363.050\n",
            "Spain               54756.030\n",
            "Belgium             40910.960\n",
            "Sweden              36585.410\n",
            "Name: TotalSales, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Total sales by country\n",
        "\n",
        "country_sales = df.groupby('Country')['TotalSales'].sum().sort_values(ascending=False)\n",
        "print(country_sales.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Description\n",
            "10 COLOUR SPACEBOY PEN                -172\n",
            "12 COLOURED PARTY BALLOONS             -20\n",
            "12 EGG HOUSE PAINTED WOOD               -1\n",
            "12 IVORY ROSE PEG PLACE SETTINGS        -1\n",
            "12 MESSAGE CARDS WITH ENVELOPES         -1\n",
            "12 PENCIL SMALL TUBE WOODLAND           -4\n",
            "12 PENCILS SMALL TUBE RED RETROSPOT   -120\n",
            "12 PENCILS SMALL TUBE SKULL           -566\n",
            "12 PENCILS TALL TUBE POSY              -24\n",
            "12 PENCILS TALL TUBE RED RETROSPOT      -7\n",
            "Name: Quantity, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Most returned products\n",
        "\n",
        "returns = df[df['Quantity'] < 0].groupby('Description')['Quantity'].sum().head(10)\n",
        "print(returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Category counts:\n",
            " ProductCategory\n",
            "Gift-Wrap           105496\n",
            "Other                77533\n",
            "Romance              39975\n",
            "Home-Light           37551\n",
            "Multi-packs          35694\n",
            "Baking               33198\n",
            "Garden               31206\n",
            "Drinkware            29066\n",
            "Christmas            15757\n",
            "Stationery           15104\n",
            "Sewing-Craft         13225\n",
            "Hardware             12607\n",
            "Signs                11344\n",
            "Decorative           10745\n",
            "Vintage-Retro        10480\n",
            "Bottles               9591\n",
            "Toys                  7820\n",
            "Wrapping              6422\n",
            "Textile               5910\n",
            "Storage               5679\n",
            "Jewellery             3726\n",
            "Halloween             3526\n",
            "First-Aid             3118\n",
            "Kitchen               2773\n",
            "Bags-Storage          2103\n",
            "Bathroom              1836\n",
            "Rain-Accessories      1050\n",
            "Aromatherapy           892\n",
            "Keyrings               695\n",
            "Magnets                562\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "    # Here i will use AI to categorize products based on keywords in their descriptions.\n",
        "    # This will help in analyzing sales by product category later.\n",
        "    # Build a keyword > category map\n",
        "    # --- keyword-to-category map ---------------------------------\n",
        "kw_cat = {\n",
        "    \"CANDLE|LIGHT|LANTERN\": \"Home-Light\",\n",
        "    \"CAKE|COOKIE|BAKE\": \"Baking\",\n",
        "    \"CARD|WRAP|GIFT|BAG|BOX\": \"Gift-Wrap\",\n",
        "    \"MUG|CUP|TEA|COFFEE\": \"Drinkware\",\n",
        "    \"PEN|PENCIL|NOTEBOOK|STICKER\": \"Stationery\",\n",
        "    \"TOY|DOLL|GAME|PUZZLE\": \"Toys\",\n",
        "    \"HEART|LOVE|WEDDING\": \"Romance\",\n",
        "    \"CHRISTMAS|XMAS|SANTA\": \"Christmas\",\n",
        "    \"SKULL|HALLOWEEN\": \"Halloween\",\n",
        "    \"GARDEN|PLANT|POT\": \"Garden\",\n",
        "    \"FABRIC|CUSHION|APRON|TOWEL\": \"Textile\",\n",
        "    \"METAL SIGN|PLAQUE\": \"Signs\",\n",
        "    \"BOTTLE|WATER|HOTTIE\": \"Bottles\",\n",
        "    \"HOOK|HANGER|DOOR\": \"Hardware\",\n",
        "    \"BAG|SHOPPER|LUNCH BAG|JUMBO BAG\": \"Bags-Storage\",\n",
        "    \"SET|PACK OF|PACK|ASSORTED\": \"Multi-packs\",\n",
        "    \"VINTAGE|RETRO|ANTIQUE\": \"Vintage-Retro\",\n",
        "    \"DECORATION|DECOR|ORNAMENT|GARLAND|BUNTING\": \"Decorative\",\n",
        "    \"KITCHEN|OVEN GLOVE|TEA TOWEL|APRON|CAKE STAND\": \"Kitchen\",\n",
        "    \"BATH|SPONGE|FLANNEL|TOWEL\": \"Bathroom\",\n",
        "    \"SEWING|THREAD|NEEDLE|PIN|KIT\": \"Sewing-Craft\",\n",
        "    \"INCENSE|OIL BURNER|SCENTED|LAVENDER\": \"Aromatherapy\",\n",
        "    \"UMBRELLA|RAIN|PONCHO\": \"Rain-Accessories\",\n",
        "    \"DOORMAT|DOOR MAT\": \"Doormats\",\n",
        "    \"FIRST AID|PLASTER|BANDAGE\": \"First-Aid\",\n",
        "    \"STORAGE|BOX|TIN|JAR|ORGANISER\": \"Storage\",\n",
        "    \"KEYRING|KEY RING\": \"Keyrings\",\n",
        "    \"JEWELLERY|NECKLACE|BRACELET|EARRING|RING\": \"Jewellery\",\n",
        "    \"MAGNET|FRIDGE MAGNET\": \"Magnets\",\n",
        "    \"WRAP|GIFT WRAP|RIBBON|BOW|TISSUE\": \"Wrapping\",\n",
        "}\n",
        "\n",
        "# ---------- categorizer function ----------\n",
        "import re\n",
        "\n",
        "def categorize(desc: str) -> str:\n",
        "    if pd.isna(desc):\n",
        "        return \"Unknown\"\n",
        "    desc_up = desc.upper()\n",
        "    for pattern, cat in kw_cat.items():\n",
        "        if re.search(pattern, desc_up):\n",
        "            return cat\n",
        "    return \"Other\"\n",
        "\n",
        "# ---------- apply ----------\n",
        "df[\"ProductCategory\"] = df[\"Description\"].apply(categorize)\n",
        "\n",
        "# sanity check\n",
        "print(\"Category counts:\\n\", df[\"ProductCategory\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 306,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Top 10 Most Expensive Products (by UnitPrice) ===\n",
            "         StockCode                     Description  UnitPrice\n",
            "4778             M                          Manual   38970.00\n",
            "4759     AMAZONFEE                      AMAZON FEE   17836.46\n",
            "4760             B                 Adjust bad debt   11062.06\n",
            "4780          POST                         POSTAGE    8142.75\n",
            "4777           DOT                  DOTCOM POSTAGE    4505.17\n",
            "4764             D                        Discount    1867.86\n",
            "4763          CRUK                 CRUK Commission    1100.44\n",
            "4761  BANK CHARGES                    Bank Charges    1050.15\n",
            "1643         22502  PICNIC BASKET WICKER 60 PIECES     649.50\n",
            "4781             S                         SAMPLES     570.00\n"
          ]
        }
      ],
      "source": [
        "top_expensive_products = (\n",
        "    df.groupby(['StockCode', 'Description'])['UnitPrice']\n",
        "      .max()   # take the maximum unit price per product\n",
        "      .reset_index()\n",
        "      .sort_values(by='UnitPrice', ascending=False)\n",
        "      .head(10)\n",
        ")\n",
        "\n",
        "print(\"\\n=== Top 10 Most Expensive Products (by UnitPrice) ===\")\n",
        "print(top_expensive_products)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ProductCategory\n",
            "Gift-Wrap           19.73\n",
            "Other               14.50\n",
            "Romance              7.48\n",
            "Home-Light           7.02\n",
            "Multi-packs          6.68\n",
            "Baking               6.21\n",
            "Garden               5.84\n",
            "Drinkware            5.44\n",
            "Christmas            2.95\n",
            "Stationery           2.82\n",
            "Sewing-Craft         2.47\n",
            "Hardware             2.36\n",
            "Signs                2.12\n",
            "Decorative           2.01\n",
            "Vintage-Retro        1.96\n",
            "Bottles              1.79\n",
            "Toys                 1.46\n",
            "Wrapping             1.20\n",
            "Textile              1.11\n",
            "Storage              1.06\n",
            "Jewellery            0.70\n",
            "Halloween            0.66\n",
            "First-Aid            0.58\n",
            "Kitchen              0.52\n",
            "Bags-Storage         0.39\n",
            "Bathroom             0.34\n",
            "Rain-Accessories     0.20\n",
            "Aromatherapy         0.17\n",
            "Keyrings             0.13\n",
            "Magnets              0.11\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Value count listed by percentages\n",
        "valcount = df['ProductCategory'].value_counts(normalize=True).mul(100).round(2)\n",
        "print(valcount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77533 rows still in Other\n",
            "Description\n",
            "POSTAGE                               1249\n",
            "WOODEN PICTURE FRAME WHITE FINISH     1123\n",
            "POPCORN HOLDER                         860\n",
            "HOME BUILDING BLOCK WORD               791\n",
            "GUMBALL COAT RACK                      717\n",
            "DOTCOM POSTAGE                         709\n",
            "WOOD BLACK BOARD ANT WHITE FINISH      696\n",
            "HAND OVER THE CHOCOLATE   SIGN         682\n",
            "HAND WARMER OWL DESIGN                 677\n",
            "SMALL POPCORN HOLDER                   607\n",
            "WOOD 2 DRAWER CABINET WHITE FINISH     588\n",
            "HAND WARMER SCOTTY DOG DESIGN          567\n",
            "Manual                                 567\n",
            "HAND WARMER BIRD DESIGN                567\n",
            "FELTCRAFT 6 FLOWER FRIENDS             561\n",
            "EDWARDIAN PARASOL NATURAL              549\n",
            "WORLD WAR 2 GLIDERS ASSTD DESIGNS      539\n",
            "ENAMEL FLOWER JUG CREAM                525\n",
            "PHOTO FRAME CORNICE                    524\n",
            "NATURAL SLATE CHALKBOARD LARGE         509\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Displaying what items are in the \"Other\" Category\n",
        "\n",
        "other_mask = df['ProductCategory'].eq('Other')\n",
        "print(other_mask.sum(), \"rows still in Other\")\n",
        "# Top 20 descriptions that are uncategorised\n",
        "print(df.loc[other_mask, 'Description'].value_counts().head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  TotalSales  \\\n",
            "0 2010-12-01 08:26:00       2.55       17850  United Kingdom       15.30   \n",
            "1 2010-12-01 08:26:00       3.39       17850  United Kingdom       20.34   \n",
            "2 2010-12-01 08:26:00       2.75       17850  United Kingdom       22.00   \n",
            "3 2010-12-01 08:26:00       3.39       17850  United Kingdom       20.34   \n",
            "4 2010-12-01 08:26:00       3.39       17850  United Kingdom       20.34   \n",
            "\n",
            "  ProductCategory  \n",
            "0      Home-Light  \n",
            "1      Home-Light  \n",
            "2       Drinkware  \n",
            "3         Bottles  \n",
            "4         Romance  \n"
          ]
        }
      ],
      "source": [
        "df.head()\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Country\n",
            "United Kingdom    8167128.184\n",
            "Netherlands        284661.540\n",
            "Ireland            262993.380\n",
            "Germany            221509.470\n",
            "France             197317.110\n",
            "Australia          137009.770\n",
            "Switzerland         56363.050\n",
            "Spain               54756.030\n",
            "Belgium             40910.960\n",
            "Sweden              36585.410\n",
            "Name: TotalSales, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "country_sales = df.groupby('Country')['TotalSales'].sum().sort_values(ascending=False)\n",
        "print(country_sales.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Top 10 Products by Quantity Sold ===\n",
            "Description\n",
            "WORLD WAR 2 GLIDERS ASSTD DESIGNS     53655\n",
            "JUMBO BAG RED RETROSPOT               47260\n",
            "POPCORN HOLDER                        36319\n",
            "ASSORTED COLOUR BIRD ORNAMENT         36260\n",
            "PACK OF 72 RETROSPOT CAKE CASES       35979\n",
            "WHITE HANGING HEART T-LIGHT HOLDER    35298\n",
            "RABBIT NIGHT LIGHT                    30618\n",
            "MINI PAINT SET VINTAGE                26437\n",
            "PACK OF 12 LONDON TISSUES             26299\n",
            "PACK OF 60 PINK PAISLEY CAKE CASES    24693\n",
            "Name: Quantity, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "top_products_qty = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\n",
        "\n",
        "print(\"\\n=== Top 10 Products by Quantity Sold ===\")\n",
        "print(top_products_qty)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Top 10 Products by Quantity Sold (with StockCode) ===\n",
            "StockCode  Description                       \n",
            "84077      WORLD WAR 2 GLIDERS ASSTD DESIGNS     53655\n",
            "85099B     JUMBO BAG RED RETROSPOT               47260\n",
            "22197      POPCORN HOLDER                        36319\n",
            "84879      ASSORTED COLOUR BIRD ORNAMENT         36260\n",
            "21212      PACK OF 72 RETROSPOT CAKE CASES       35979\n",
            "85123A     WHITE HANGING HEART T-LIGHT HOLDER    35006\n",
            "23084      RABBIT NIGHT LIGHT                    30618\n",
            "22492      MINI PAINT SET VINTAGE                26437\n",
            "22616      PACK OF 12 LONDON TISSUES             26299\n",
            "21977      PACK OF 60 PINK PAISLEY CAKE CASES    24693\n",
            "Name: Quantity, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "top_products_qty = (\n",
        "    df.groupby(['StockCode', 'Description'])['Quantity']\n",
        "      .sum()\n",
        "      .sort_values(ascending=False)\n",
        "      .head(10)\n",
        ")\n",
        "\n",
        "print(\"\\n=== Top 10 Products by Quantity Sold (with StockCode) ===\")\n",
        "print(top_products_qty)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Sales by Day of Week ===\n",
            "DayOfWeek\n",
            "Thursday     2106396.810\n",
            "Tuesday      1964659.531\n",
            "Wednesday    1729755.230\n",
            "Monday       1583834.391\n",
            "Friday       1537055.891\n",
            "Sunday        798272.411\n",
            "Name: TotalSales, dtype: float64\n",
            "\n",
            "=== Sales by Hour of Day ===\n",
            "Hour\n",
            "6        -497.350\n",
            "7       31009.320\n",
            "8      281723.020\n",
            "9      766280.621\n",
            "10    1325875.591\n",
            "11    1146457.490\n",
            "12    1356923.770\n",
            "13    1172205.450\n",
            "14    1090776.191\n",
            "15    1185780.950\n",
            "16     726454.610\n",
            "17     434834.541\n",
            "18     140365.040\n",
            "19      45864.930\n",
            "20      15920.090\n",
            "Name: TotalSales, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "df['DayOfWeek'] = df['InvoiceDate'].dt.day_name()\n",
        "df['Hour'] = df['InvoiceDate'].dt.hour\n",
        "\n",
        "sales_by_day = df.groupby('DayOfWeek')['TotalSales'].sum().sort_values(ascending=False)\n",
        "sales_by_hour = df.groupby('Hour')['TotalSales'].sum()\n",
        "\n",
        "print(\"\\n=== Sales by Day of Week ===\")\n",
        "print(sales_by_day)\n",
        "\n",
        "print(\"\\n=== Sales by Hour of Day ===\")\n",
        "print(sales_by_hour)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Top 10 Returned Products (by Quantity) ===\n",
            "Description\n",
            "PAPER CRAFT , LITTLE BIRDIE           -80995\n",
            "MEDIUM CERAMIC TOP STORAGE JAR        -74494\n",
            "printing smudges/thrown away          -19200\n",
            "Unsaleable, destroyed.                -15644\n",
            "check                                 -13247\n",
            "?                                      -9496\n",
            "ROTATING SILVER ANGELS T-LIGHT HLDR    -9376\n",
            "Printing smudges/thrown away           -9058\n",
            "Damaged                                -7540\n",
            "throw away                             -5368\n",
            "Name: Quantity, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Hightest returned products\n",
        "\n",
        "returns = df[df['Quantity'] < 0].groupby('Description')['Quantity'].sum().sort_values().head(10)\n",
        "\n",
        "print(\"\\n=== Top 10 Returned Products (by Quantity) ===\")\n",
        "print(returns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Top 10 Customers by Number of Orders ===\n",
            "CustomerID\n",
            "15287    2254\n",
            "14911     248\n",
            "12748     224\n",
            "17841     169\n",
            "14606     128\n",
            "15311     118\n",
            "13089     118\n",
            "12971      89\n",
            "14527      86\n",
            "13408      81\n",
            "Name: InvoiceNo, dtype: int64\n",
            "\n",
            "=== Orders by Country (Top 10) ===\n",
            "Country\n",
            "United Kingdom    22040\n",
            "Germany             603\n",
            "France              461\n",
            "Ireland             360\n",
            "Belgium             119\n",
            "Spain               105\n",
            "Netherlands         101\n",
            "Switzerland          74\n",
            "Portugal             71\n",
            "Australia            69\n",
            "Name: InvoiceNo, dtype: int64\n",
            "\n",
            "=== Top 10 Products by Number of Orders ===\n",
            "Description\n",
            "WHITE HANGING HEART T-LIGHT HOLDER    2302\n",
            "REGENCY CAKESTAND 3 TIER              2167\n",
            "JUMBO BAG RED RETROSPOT               2135\n",
            "PARTY BUNTING                         1706\n",
            "LUNCH BAG RED RETROSPOT               1605\n",
            "ASSORTED COLOUR BIRD ORNAMENT         1464\n",
            "SET OF 3 CAKE TINS PANTRY DESIGN      1457\n",
            "PACK OF 72 RETROSPOT CAKE CASES       1332\n",
            "LUNCH BAG  BLACK SKULL.               1294\n",
            "NATURAL SLATE HEART CHALKBOARD        1265\n",
            "Name: InvoiceNo, dtype: int64\n",
            "\n",
            "Total unique customers: 4367\n",
            "Total unique countries: 36\n",
            "Total unique products: 4211\n",
            "Total unique orders: 24428\n"
          ]
        }
      ],
      "source": [
        "# Count how many unique invoices each customer has\n",
        "orders_by_user = df.groupby('CustomerID')['InvoiceNo'].nunique().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\n=== Top 10 Customers by Number of Orders ===\")\n",
        "print(orders_by_user.head(10))\n",
        "\n",
        "\n",
        "orders_by_country = df.groupby('Country')['InvoiceNo'].nunique().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\n=== Orders by Country (Top 10) ===\")\n",
        "print(orders_by_country.head(10))\n",
        "\n",
        "\n",
        "orders_by_product = df.groupby('Description')['InvoiceNo'].nunique().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\n=== Top 10 Products by Number of Orders ===\")\n",
        "print(orders_by_product.head(10))\n",
        "\n",
        "\n",
        "print(\"\\nTotal unique customers:\", df['CustomerID'].nunique())\n",
        "print(\"Total unique countries:\", df['Country'].nunique())\n",
        "print(\"Total unique products:\", df['Description'].nunique())\n",
        "print(\"Total unique orders:\", df['InvoiceNo'].nunique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 312,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RFM head:\n",
            "   CustomerID  Recency  Frequency  Monetary  R_score  F_score  M_score  \\\n",
            "0       12346      325          1  77183.60        1        1        4   \n",
            "1       12347        1          7   4310.00        4        4        4   \n",
            "2       12348       74          4   1797.24        2        3        4   \n",
            "3       12349       18          1   1757.55        3        1        4   \n",
            "4       12350      309          1    334.40        1        1        2   \n",
            "\n",
            "   RFM_Score  \n",
            "0          6  \n",
            "1         12  \n",
            "2          9  \n",
            "3          8  \n",
            "4          4  \n",
            "Champions count: 1260\n",
            "Champions contribute 80.53% of total revenue\n"
          ]
        }
      ],
      "source": [
        "# The following blocks of code will help support hypotheses 2 in the README.md file.\n",
        "# AI helped generate this code to support the hypothesis.\n",
        "\n",
        "\n",
        "# (A) Use only positive lines for Monetary (exclude returns)\n",
        "base = df[df['Quantity'] > 0].copy()\n",
        "\n",
        "# (B) Drop Guest customers if you used -1 as placeholder\n",
        "base = base[base['CustomerID'] != -1].copy()\n",
        "\n",
        "# 2) Compute RFM\n",
        "latest = base['InvoiceDate'].max()\n",
        "rfm = base.groupby('CustomerID').agg(\n",
        "    Recency=('InvoiceDate', lambda s: (latest - s.max()).days),\n",
        "    Frequency=('InvoiceNo', 'nunique'),\n",
        "    Monetary=('TotalSales', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# 3) Clean edge cases: drop zero/negative or NaNs that break binning\n",
        "rfm = rfm.replace([np.inf, -np.inf], np.nan).dropna(subset=['Recency','Frequency','Monetary'])\n",
        "rfm = rfm[rfm['Frequency'] > 0]              # must have at least 1 order\n",
        "rfm = rfm[rfm['Monetary'] >= 0]              # keep non-negative spend\n",
        "\n",
        "# 4) Rank-based quartiles (avoids \"bin edges must be unique\")\n",
        "#    - For Recency: lower is better â†’ invert labels (4 best to 1 worst)\n",
        "rfm['R_score'] = pd.qcut(rfm['Recency'].rank(method='first'), 4, labels=[4,3,2,1]).astype(int)\n",
        "rfm['F_score'] = pd.qcut(rfm['Frequency'].rank(method='first'), 4, labels=[1,2,3,4]).astype(int)\n",
        "rfm['M_score'] = pd.qcut(rfm['Monetary'].rank(method='first'), 4, labels=[1,2,3,4]).astype(int)\n",
        "\n",
        "rfm['RFM_Score'] = rfm[['R_score','F_score','M_score']].sum(axis=1)\n",
        "\n",
        "print(\"RFM head:\")\n",
        "print(rfm.head())\n",
        "\n",
        "# 5) Define Champions (top tier)\n",
        "champions = rfm[rfm['RFM_Score'] >= 10].copy()  # 10â€“12\n",
        "print(\"Champions count:\", champions.shape[0])\n",
        "\n",
        "# 6) Revenue share check\n",
        "total_revenue = base['TotalSales'].sum()\n",
        "champions_revenue = champions['Monetary'].sum()\n",
        "share = champions_revenue / total_revenue * 100\n",
        "print(f\"Champions contribute {share:.2f}% of total revenue\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# As we can see above even though champions equate to only a small fraction of customers they contribute to over 80% of total revenue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Cleaned dataset saved as ZIP at: C:\\Users\\Nine\\OneDrive\\Documents\\VS Code Projects\\online-retail-transactions-analysis\\DataSet\\Cleaned\\fact_sales_clean.zip\n"
          ]
        }
      ],
      "source": [
        "# Here we had issues with saving the cleaned dataset as the file was too large for GitHub.\n",
        "# To solve this we will save the cleaned dataset as a CSV inside a ZIP archive.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Define your cleaned data folder\n",
        "CLEAN_DIR = Path(r\"C:\\Users\\Nine\\OneDrive\\Documents\\VS Code Projects\\online-retail-transactions-analysis\\DataSet\\Cleaned\")\n",
        "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save as CSV inside a ZIP archive\n",
        "zip_path = CLEAN_DIR / \"fact_sales_clean.zip\"\n",
        "df.to_csv(zip_path, index=False, compression='zip')\n",
        "\n",
        "print(f\"âœ… Cleaned dataset saved as ZIP at: {zip_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ZIP file size: 9.67 MB\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "size_mb = os.path.getsize(zip_path) / (1024*1024)\n",
        "print(f\"ZIP file size: {size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 305,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The ZIP file is now under 100MB and can be uploaded to GitHub without issues.\n",
        "# In future, I will not extract the Kaggle dataset but will keep it in its original ZIP format to avoid this issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
